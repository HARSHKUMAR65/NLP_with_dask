{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2gi_qJgWFAP",
    "outputId": "996df96a-182d-4859-97ef-b388d20a0be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
      "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
      "Collecting partd>=0.3.10\n",
      "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2018.9)\n",
      "Collecting locket\n",
      "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
      "Installing collected packages: locket, partd, fsspec\n",
      "Successfully installed fsspec-2021.7.0 locket-0.2.1 partd-1.2.0\n"
     ]
    }
   ],
   "source": [
    " pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC7FIHkCwRTs"
   },
   "source": [
    "###importing necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dsjm_K-MWmZK"
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from itertools import filterfalse\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUMGmAjZwaZU"
   },
   "source": [
    "###Read data with dask Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "zjlCTKwa_JPM",
    "outputId": "8d096a4f-b6dd-49ec-c206-d06d73a6426f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-09 18:31:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Lee Drutman</td>\n",
       "      <td>We should take concerns about the health of li...</td>\n",
       "      <td>This post is part of Polyarchy, an independent...</td>\n",
       "      <td>https://www.vox.com/polyarchy/2016/12/9/138983...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-07 21:26:46</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Scott Davis</td>\n",
       "      <td>Colts GM Ryan Grigson says Andrew Luck's contr...</td>\n",
       "      <td>The Indianapolis Colts made Andrew Luck the h...</td>\n",
       "      <td>https://www.businessinsider.com/colts-gm-ryan-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-26 00:00:00</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump denies report he ordered Mueller fired</td>\n",
       "      <td>DAVOS, Switzerland (Reuters) - U.S. President ...</td>\n",
       "      <td>https://www.reuters.com/article/us-davos-meeti...</td>\n",
       "      <td>Davos</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-06-27 00:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France's Sarkozy reveals his 'Passions' but in...</td>\n",
       "      <td>PARIS (Reuters) - Former French president Nico...</td>\n",
       "      <td>https://www.reuters.com/article/france-politic...</td>\n",
       "      <td>World News</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-27 00:00:00</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris Hilton: Woman In Black For Uncle Monty's...</td>\n",
       "      <td>Paris Hilton arrived at LAX Wednesday dressed ...</td>\n",
       "      <td>https://www.tmz.com/2016/01/27/paris-hilton-mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TMZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Unnamed: 0.1  ...     section       publication\n",
       "0          0            0  ...         NaN               Vox\n",
       "1          1            1  ...         NaN  Business Insider\n",
       "2          2            2  ...       Davos           Reuters\n",
       "3          3            3  ...  World News           Reuters\n",
       "4          4            4  ...         NaN               TMZ\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =dd.read_csv(\"all-the-news-2-1.csv\",error_bad_lines=False,engine='python',encoding=\"utf8\"\n",
    "                  ,dtype={'Unnamed: 0':'object','Unnamed: 0.1':'object','day':'object','year':'object','month':'object'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hV3YhrNGwfjE"
   },
   "source": [
    "###Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Og0FsEW_J1r9"
   },
   "outputs": [],
   "source": [
    "df=data.drop(['Unnamed: 0','Unnamed: 0.1','url','section','author','day','month','date','year','publication'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_VR1FsPKD8k",
    "outputId": "a4a298ae-b143-4fc9-b2bd-b5a3353d9c0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      object\n",
       "article    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.fillna(0)  ##Fill na with zero\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXctw346wu6b"
   },
   "source": [
    "###combining the title and article column text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lfkTfOD11JCP"
   },
   "outputs": [],
   "source": [
    "columns=data.columns\n",
    "data['text']=data[columns].apply(func=(lambda row: ' '.join(row.values.astype(str))) ,axis=1,meta=('str'))\n",
    "data=data.drop(columns,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rslQrKFpw3gC"
   },
   "source": [
    "##**text preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJ_pF0L96vm6",
    "outputId": "e2fc1a69-4da1-4852-fd98-b0b8c5681916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StfDLdhZ2n-M",
    "outputId": "3442410f-fe31-40f2-ae24-971942d4ef64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ljLOmLDMKd7f"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: word_tokenize(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "oyCVpSaxAgrE",
    "outputId": "0756efbc-492d-4ea8-8559-ffcee2143632"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[We, should, take, concerns, about, the, healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Colts, GM, Ryan, Grigson, says, Andrew, Luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Trump, denies, report, he, ordered, Mueller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[France, 's, Sarkozy, reveals, his, 'Passions,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Paris, Hilton, :, Woman, In, Black, For, Uncl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [We, should, take, concerns, about, the, healt...\n",
       "1  [Colts, GM, Ryan, Grigson, says, Andrew, Luck,...\n",
       "2  [Trump, denies, report, he, ordered, Mueller, ...\n",
       "3  [France, 's, Sarkozy, reveals, his, 'Passions,...\n",
       "4  [Paris, Hilton, :, Woman, In, Black, For, Uncl..."
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "COHY6VtFKlVn"
   },
   "outputs": [],
   "source": [
    "def normalize_tokens(list_of_tokens):\n",
    "    return map(lambda x: x.lower(),list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FZ0vK_wQKr_v"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: normalize_tokens(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "avwFYa9I1sx_"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-643FTrnBcSd",
    "outputId": "a1d8b19f-805f-4aa7-b232-256a2698b119"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, 's, sarkozy, reveals, his, 'passions,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, :, woman, in, black, for, uncl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [we, should, take, concerns, about, the, healt...\n",
       "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
       "2  [trump, denies, report, he, ordered, mueller, ...\n",
       "3  [france, 's, sarkozy, reveals, his, 'passions,...\n",
       "4  [paris, hilton, :, woman, in, black, for, uncl..."
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHoGu90T2oCG",
    "outputId": "74bafa12-063e-4e2a-ff02-d5e88bba91df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yy1uxt8Knu5C"
   },
   "outputs": [],
   "source": [
    "def contracted_word_expansion(token):\n",
    "    if token in contractions_dict.keys():\n",
    "        return contractions_dict[token]\n",
    "    else:\n",
    "        return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_mNc_TkCny7X"
   },
   "outputs": [],
   "source": [
    "def contractions_expansion(list_of_tokens):\n",
    "    return map(contracted_word_expansion,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nTeYtITgn1Pd"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: contractions_expansion(x),meta=('text'))\n",
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "XY2xxrFoBe_o",
    "outputId": "84992829-c971-4925-a221-5dc9d6326e04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, 's, sarkozy, reveals, his, 'passions,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, :, woman, in, black, for, uncl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [we, should, take, concerns, about, the, healt...\n",
       "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
       "2  [trump, denies, report, he, ordered, mueller, ...\n",
       "3  [france, 's, sarkozy, reveals, his, 'passions,...\n",
       "4  [paris, hilton, :, woman, in, black, for, uncl..."
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QPfvlTbSotrY"
   },
   "outputs": [],
   "source": [
    "regex = r'^@[a-zA-z0-9]|^#[a-zA-Z0-9]|\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*|\\W+|\\d+|<(\"[^\"]*\"|\\'[^\\']*\\'|[^\\'\">])*>|_+|[^\\u0000-\\u007f]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xBz0YtSFn5X5"
   },
   "outputs": [],
   "source": [
    "def waste_word_or_not(token):\n",
    "    return re.search(regex,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3zVnK-DJn-uG"
   },
   "outputs": [],
   "source": [
    "def filter_waste_words(list_of_tokens):\n",
    "    return filterfalse(waste_word_or_not,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AuQVs33OoA25"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: filter_waste_words(x),meta=('text'))\n",
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "PEIG_cGdBhSx",
    "outputId": "34b3e858-5992-4405-f9cb-b9b377dc8db1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, sarkozy, reveals, his, but, insists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, woman, in, black, for, uncle, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [we, should, take, concerns, about, the, healt...\n",
       "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
       "2  [trump, denies, report, he, ordered, mueller, ...\n",
       "3  [france, sarkozy, reveals, his, but, insists, ...\n",
       "4  [paris, hilton, woman, in, black, for, uncle, ..."
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SuOY5ik7oKxu"
   },
   "outputs": [],
   "source": [
    "def split(list_of_tokens):\n",
    "    return map(lambda x: re.split(regex,x)[0],list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2zZzR0yCoEsU"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: split(x),meta=('text'))\n",
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Mzd1ltDYBkFS",
    "outputId": "688843ba-77d1-4fb6-bea5-c57d15caf3bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[we, should, take, concerns, about, the, healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, he, ordered, mueller, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, sarkozy, reveals, his, but, insists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, woman, in, black, for, uncle, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [we, should, take, concerns, about, the, healt...\n",
       "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
       "2  [trump, denies, report, he, ordered, mueller, ...\n",
       "3  [france, sarkozy, reveals, his, but, insists, ...\n",
       "4  [paris, hilton, woman, in, black, for, uncle, ..."
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3i6em57DaYX",
    "outputId": "5188007f-047a-4038-a51f-29f54f51d942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0Uv9OtMNRx4I"
   },
   "outputs": [],
   "source": [
    "en_stop_words = list(set(stopwords.words('english')).union(set(STOP_WORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ixrcym0Q2f3R"
   },
   "outputs": [],
   "source": [
    "def is_stopword(token):\n",
    "    return not(token in en_stop_words or re.search(r'\\b\\w\\b|[^\\u0000-\\u007f]+|_+|\\W+',token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0pVoBUE42gLA"
   },
   "outputs": [],
   "source": [
    "def stopwords_removal(list_of_tokens):\n",
    "    return filter(is_stopword,list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Qhhwpzpi2i2X"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: stopwords_removal(x),meta=('text'))\n",
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "MpGhLk6YBmhQ",
    "outputId": "0e3a1a1d-d66c-47ca-d2cf-add5916cb1e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[concerns, health, liberal, democracy, serious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colts, gm, ryan, grigson, says, andrew, luck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, ordered, mueller, fire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, sarkozy, reveals, insists, cards, par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, woman, black, uncle, monty, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [concerns, health, liberal, democracy, serious...\n",
       "1  [colts, gm, ryan, grigson, says, andrew, luck,...\n",
       "2  [trump, denies, report, ordered, mueller, fire...\n",
       "3  [france, sarkozy, reveals, insists, cards, par...\n",
       "4  [paris, hilton, woman, black, uncle, monty, fu..."
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Fu4kZmcV2oPN"
   },
   "outputs": [],
   "source": [
    "def get_wnet_pos_tag(treebank_tag):\n",
    "    if treebank_tag[1].startswith('J'):\n",
    "        return (treebank_tag[0],wordnet.ADJ)\n",
    "    elif treebank_tag[1].startswith('V'):\n",
    "        return (treebank_tag[0],wordnet.VERB)\n",
    "    elif treebank_tag[1].startswith('N'):\n",
    "        return (treebank_tag[0],wordnet.NOUN)\n",
    "    elif treebank_tag[1].startswith('R'):\n",
    "        return (treebank_tag[0],wordnet.ADV)\n",
    "    else:\n",
    "        (treebank_tag[0],wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuScd8ISDI6u",
    "outputId": "0dd621d4-495e-4c10-bfb2-38d80f3699e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XN0tnQsrDNuM",
    "outputId": "65742ca7-526d-4bdb-8403-4f7d00fb4180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "g7pYgens2n7f"
   },
   "outputs": [],
   "source": [
    "def get_pos_tag(list_of_tokens):\n",
    "    return map(get_wnet_pos_tag,pos_tag(list_of_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uh9sACeyIZ1d",
    "outputId": "4ac883d3-d043-42d8-eb80-3507f965ec30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "1fBvtkQY2n5I"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: get_pos_tag(x),meta=('text'))\n",
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "FEgOIbbaBqbJ",
    "outputId": "01985843-c305-4f46-d02a-3d4f1c974260"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(concerns, n), (health, n), (liberal, a), (de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(colts, n), (gm, v), (ryan, a), (grigson, n),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(trump, n), (denies, n), (report, n), (ordere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(france, n), (sarkozy, n), (reveals, n), (ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(paris, a), (hilton, n), (woman, n), (black, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [(concerns, n), (health, n), (liberal, a), (de...\n",
       "1  [(colts, n), (gm, v), (ryan, a), (grigson, n),...\n",
       "2  [(trump, n), (denies, n), (report, n), (ordere...\n",
       "3  [(france, n), (sarkozy, n), (reveals, n), (ins...\n",
       "4  [(paris, a), (hilton, n), (woman, n), (black, ..."
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0Bo-ewlv233g"
   },
   "outputs": [],
   "source": [
    " lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2XMm3TVv23ze"
   },
   "outputs": [],
   "source": [
    "def token_lemmatization(token_pos_tuple):\n",
    "    if token_pos_tuple == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word=token_pos_tuple[0],pos=token_pos_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "R6odmjRL23w7"
   },
   "outputs": [],
   "source": [
    "def lemmatization(list_of_tokens):\n",
    "    if len(list_of_tokens) > 0:\n",
    "        return map(lambda x: token_lemmatization(x),list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "b3L1j3yB23uP"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: lemmatization(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "wEU8Deii23rn"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: list(x),meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "wzXAHV9MRxT3",
    "outputId": "267bc96f-9fb7-4213-9f48-e5c172f0dd6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[concern, health, liberal, democracy, seriousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colt, gm, ryan, grigson, say, , luck, contrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[trump, denies, report, order, mueller, fire, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[france, sarkozy, reveals, insist, card, paris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, hilton, woman, black, uncle, monty, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [concern, health, liberal, democracy, seriousl...\n",
       "1  [colt, gm, ryan, grigson, say, , luck, contrac...\n",
       "2  [trump, denies, report, order, mueller, fire, ...\n",
       "3  [france, sarkozy, reveals, insist, card, paris...\n",
       "4  [paris, hilton, woman, black, uncle, monty, fu..."
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k40gAljxBEn"
   },
   "source": [
    "##**most frequent word for each row**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qStkApyRrSfP"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Ad0KWfobVNLB"
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: [k for k, v in Counter(x).most_common(50)],meta=('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "HupoQyUOfOPE",
    "outputId": "5276fbfc-3a9e-4f5a-bd77-d3e6cb312d52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[democracy, heart, attack, seriously, foa, mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[colt, , luck, defense, contract, team, grigso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[report, trump, order, fake, news, mueller, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sarkozy, return, party, president, politics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paris, monty, hilton, uncle, funeral, brinson...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [democracy, heart, attack, seriously, foa, mou...\n",
       "1  [colt, , luck, defense, contract, team, grigso...\n",
       "2  [report, trump, order, fake, news, mueller, fi...\n",
       "3  [sarkozy, return, party, president, politics, ...\n",
       "4  [paris, monty, hilton, uncle, funeral, brinson..."
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "all news data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
